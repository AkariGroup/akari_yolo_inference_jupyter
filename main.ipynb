{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ff449-f367-4587-acdc-b0063c8c3f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import blobconverter\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# ここのパスにmodel(.blob),config(.json)のパスを記載\n",
    "MODEL_PATH = 'yolov4_tiny_coco_416x416'\n",
    "CONFIG_PATH = 'json/yolov4-tiny.json'\n",
    "\n",
    "configPath = Path(CONFIG_PATH)\n",
    "if not configPath.exists():\n",
    "    raise ValueError(\"Path {} does not exist!\".format(configPath))\n",
    "\n",
    "with configPath.open() as f:\n",
    "    config = json.load(f)\n",
    "nnConfig = config.get(\"nn_config\", {})\n",
    "\n",
    "if \"input_size\" in nnConfig:\n",
    "    W, H = tuple(map(int, nnConfig.get(\"input_size\").split('x')))\n",
    "\n",
    "metadata = nnConfig.get(\"NN_specific_metadata\", {})\n",
    "classes = metadata.get(\"classes\", {})\n",
    "coordinates = metadata.get(\"coordinates\", {})\n",
    "anchors = metadata.get(\"anchors\", {})\n",
    "anchorMasks = metadata.get(\"anchor_masks\", {})\n",
    "iouThreshold = metadata.get(\"iou_threshold\", {})\n",
    "confidenceThreshold = metadata.get(\"confidence_threshold\", {})\n",
    "\n",
    "print(metadata)\n",
    "\n",
    "nnMappings = config.get(\"mappings\", {})\n",
    "labels = nnMappings.get(\"labels\", {})\n",
    "\n",
    "nnPath = MODEL_PATH\n",
    "if not Path(nnPath).exists():\n",
    "    print(\"No blob found at {}. Looking into DepthAI model zoo.\".format(nnPath))\n",
    "    nnPath = str(blobconverter.from_zoo(MODEL_PATH, shaves = 6, zoo_type = \"depthai\", use_cache=True))\n",
    "syncNN = True\n",
    "\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "camRgb = pipeline.create(dai.node.ColorCamera)\n",
    "detectionNetwork = pipeline.create(dai.node.YoloDetectionNetwork)\n",
    "xoutRgb = pipeline.create(dai.node.XLinkOut)\n",
    "nnOut = pipeline.create(dai.node.XLinkOut)\n",
    "\n",
    "xoutRgb.setStreamName(\"rgb\")\n",
    "nnOut.setStreamName(\"nn\")\n",
    "\n",
    "# Properties\n",
    "camRgb.setPreviewKeepAspectRatio(False)\n",
    "\n",
    "camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "camRgb.setInterleaved(False)\n",
    "camRgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.BGR)\n",
    "camRgb.setPreviewSize(1920, 1080)\n",
    "camRgb.setFps(10)\n",
    "\n",
    "xoutIsp = pipeline.create(dai.node.XLinkOut)\n",
    "xoutIsp.setStreamName(\"isp\")\n",
    "camRgb.isp.link(xoutIsp.input)\n",
    "\n",
    "manip = pipeline.create(dai.node.ImageManip)\n",
    "manip.setMaxOutputFrameSize(W * H * 3) # 640x640x3\n",
    "manip.initialConfig.setResizeThumbnail(W, H)\n",
    "camRgb.preview.link(manip.inputImage)\n",
    "\n",
    "detectionNetwork.setConfidenceThreshold(confidenceThreshold)\n",
    "detectionNetwork.setNumClasses(classes)\n",
    "detectionNetwork.setCoordinateSize(coordinates)\n",
    "detectionNetwork.setAnchors(anchors)\n",
    "detectionNetwork.setAnchorMasks(anchorMasks)\n",
    "detectionNetwork.setIouThreshold(iouThreshold)\n",
    "detectionNetwork.setBlobPath(nnPath)\n",
    "detectionNetwork.setNumInferenceThreads(2)\n",
    "detectionNetwork.input.setBlocking(False)\n",
    "\n",
    "manip.out.link(detectionNetwork.input)\n",
    "detectionNetwork.passthrough.link(xoutRgb.input)\n",
    "detectionNetwork.out.link(nnOut.input)\n",
    "\n",
    "# Connect to device and start pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "\n",
    "    # Output queues will be used to get the rgb frames and nn data from the outputs defined above\n",
    "    qRgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "    qIsp = device.getOutputQueue(name='isp')\n",
    "    qDet = device.getOutputQueue(name=\"nn\", maxSize=4, blocking=False)\n",
    "\n",
    "    frame = None\n",
    "    detections = []\n",
    "    startTime = time.monotonic()\n",
    "    counter = 0\n",
    "    color2 = (255, 255, 255)\n",
    "    display_handle=display(None, display_id=True)\n",
    "\n",
    "    def frameNorm(frame, bbox):\n",
    "        normVals = np.full(len(bbox), frame.shape[0])\n",
    "        normVals[::2] = frame.shape[1]\n",
    "        return (np.clip(np.array(bbox), 0, 1) * normVals).astype(int)\n",
    "\n",
    "    def displayFrame(name, frame, detections):\n",
    "        color = (255, 0, 0)\n",
    "        # Crop the frame Square to 16:9\n",
    "        rows, columns, _ = frame.shape\n",
    "        fixed_rows = frame.shape[1] * 9 / 16\n",
    "        brank_rows = columns - fixed_rows\n",
    "        frame = frame[int(brank_rows / 2) : int(frame.shape[0] -\n",
    "                      brank_rows / 2), 0 : columns]\n",
    "        for detection in detections:\n",
    "            # Fix ymin and ymax to cropped frame pos\n",
    "            detection.ymin = ((columns / fixed_rows) * detection.ymin - (brank_rows / 2 / fixed_rows))\n",
    "            detection.ymax =  ((columns / fixed_rows) * detection.ymax - (brank_rows / 2 / fixed_rows))\n",
    "            bbox = frameNorm(frame, (detection.xmin, detection.ymin, detection.xmax, detection.ymax))\n",
    "            cv2.putText(frame, labels[detection.label], (bbox[0] + 10, bbox[1] + 20), cv2.FONT_HERSHEY_TRIPLEX, 0.5, 255)\n",
    "            cv2.putText(frame, f\"{int(detection.confidence * 100)}%\", (bbox[0] + 10, bbox[1] + 40), cv2.FONT_HERSHEY_TRIPLEX, 0.5, 255)\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "        _, jpg = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=jpg.tobytes())),\n",
    "        \n",
    "    while True:\n",
    "        inRgb = qRgb.get()\n",
    "        inIsp = qIsp.get()\n",
    "        inDet = qDet.get()\n",
    "\n",
    "        if inRgb is not None:\n",
    "            frame = inRgb.getCvFrame()\n",
    "            cv2.putText(frame, \"NN fps: {:.2f}\".format(counter / (time.monotonic() - startTime)),\n",
    "                        (2, frame.shape[0] - 4), cv2.FONT_HERSHEY_TRIPLEX, 0.4, color2)\n",
    "\n",
    "        if inDet is not None:\n",
    "            detections = inDet.detections\n",
    "            counter += 1\n",
    "\n",
    "        if frame is not None:\n",
    "            displayFrame(\"rgb\", frame, detections)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
